我叫XX，来自上海理工大学计算机技术专业，目前研二。

目前，我一段深度学习框架开发的实习经历。当时参与deeplink项目，主要是对国产的华为昇腾芯片做框架适配。

除此之外，我还有两个项目

- TinyInfer，一个深度学习推理框架，基于数学库armdillo实现tensor，然后基础上构建计算节点，算子，计算图。
- TinySTL，C++入门项目，主要熟悉C++的基本语法，STL库，C++11的一些新特性，右值，移动语义，模板推导等。内存池，数据布局。

方面：

- 熟悉Transformer，LLaMA模型，熟悉Flash Attention。我本身研究方向是高光谱图像超分辨率，对Pytorch有一定的了解，平时会训练一些网络。
- 了解GPU的架构，写过一些基本的cuda程序，例如向量加法，跨步循环，矩阵乘法。其中还对矩阵乘法做了优化。
- 熟悉linux基本命令，熟悉cmake，git等工具



## 详细实习经历

 参与的是DIOPI的开发，即设备无关算子接口。作为前端训练框架和后端芯片计算库之间的中间体，适配的功能。我们主要做的是将前端pytorch适配到华为的昇腾芯片，即CANN。

我的工作主要是分为三个部分：

- 张量基本操作实现。对于不同后端芯片，他们共享同一个基础的张量类diopiTensor，成员遍历有shape/stride/device等，它提供了基础的张量操作。然后在华为芯片上，设计了AscendTensor类，它和diopiTensor是has-a的关系，即组合方式。提供了unsqueeze，view，一些调试函数，因为各个组开发进度不一样的。比如getScalarByte函数，makeTensor/makeTensorFromScalar。比如要在设备上从值创建tensor，首先看tensor所属的设备，然后再设备上创建空的tensor，拿到scalar的值，通过fill函数来填充.
- 算子开发。先后开发了div/nlloss/atan/im2col算子。先了解算子的用法，输入输出的数据shape，dtype等信息。比如去pytorch看这个算子的文档。然后查阅CANN手册中关于这个算子的描述，比如开发div函数，pytorch中div算子支持三种mode，正常除法，floor向下取整，trunc向0取整数，在CANN刚好有这三类的实现，所以就调用，如果没有可能需要自己适配，还比如pytorch 0/0=nan 1/0=inf 但CANN底层表现不一样，还有比如底层不支持float32 f16。再比如nllloss算子，底层CANN只支持2Dtensor，对于1维的tensor，我们采用unsqueeze，对于4Dtensor需要transpose，将后两个维度累积到batch维度
- 精度验证，主要是基于mmdetection/mmpretrain等框架，准备少量数据，对比cpu模型和ascend模型的精度，层与层之间输出的数据的差。resnet，unet等。









我平时主要使用C++进行编程， 掌握C++的基本语法，掌握常见的数据结构和算法。

- 熟悉C++11的一些特性，比如智能指针，lambda表达式，移动语义，右值，异步编程等。

- 熟悉STL库，在使用的基础上，也有去了解里面的实现，特别是vector和deque。

- 看过书籍Effective C++，初始化列表，模板类型推导。

- 了解GPU的架构，GPU一般用于计算密集和数据并行的场景，这得益于它的架构。cuda提供了一层抽象，从硬件角度来讲，cuda运行的基本单位是SP，一堆SP和一块共享内存组成SM，多个SM和全局内存组成GPU。在运行一个kernel时会启动很多线程，grid/block/thread，可以向三个维度延申，处理数据一般是一维，可以做扁平化处理。运行时，block会被调度到某个SM上，SM将32个线程作为一个线程束来启动。
- cuda编程。在了解架构之后，编写最基本的向量加法，学习跨步循环。写gemm，了解一些GPU优化手段，使用共享内存，bank conflict等。
- 我自己的研究方向是高光谱图像超分，所以自己会训练一些深度学习网络，用一些模块比如CNN，RNN，Attention等。
- 在之前的实习中，熟悉了git流程。同时也熟悉linux的基本命令





